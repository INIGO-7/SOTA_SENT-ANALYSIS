{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOTA INVESTIGATION FOR SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a investigation on different models for sentiment-analysis text classification.\n",
    "\n",
    "The models used will be:\n",
    "- Phi 3.5 3.8B parameters Q4_K_M, zero-shot & few-shot\n",
    "- Llama 3.2 1B parameters Q6_K_L, zero-shot & few-shot\n",
    "- RoBERTa\n",
    "\n",
    "Also some state-of-the-art LLMs will be tested, but not with the whole length of the dataset\n",
    "- Deepseek R1\n",
    "- Gemini 2.5 pro\n",
    "- ChatGPT 4o\n",
    "\n",
    "These last models will be tested via their web-chatbot version, due to limited resources for API use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emotion_classifier import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"secrets\", \"credentials.txt\"), \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        key, value = line.split(\":\")\n",
    "\n",
    "        if key == \"huggingface\":\n",
    "            access_token = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_datasets = list(DatasetHandler.DATASET_CONFIGS.keys())\n",
    "print(f\"The available datasets are: {available_datasets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available templates:\")\n",
    "PromptTemplate.TEMPLATES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GO_EMOTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetHandler(\"go_emotions\", split=\"test\", sample=0.1, seed=28)\n",
    "print(len(dataset.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.label2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing prompts for LLM models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You're a helpful and obedient assistant that responds to questions according to the instructions given.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroshot_user_pre_prompt = f\"\"\"\n",
    "Classify text into ALL applicable emotion labels from this list: {\", \".join(dataset.labels)}, replying only with the final comma-separated predominant emotion labels detected. The text is: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshot_user_pre_prompt = f\"\"\"\n",
    "Classify text into ALL applicable emotion labels from this list: {\", \".join(dataset.labels)}, based on the following examples:\n",
    "\n",
    "Text: [NAME], loved the story. Personally I don’t think this was petty I think it was quite fair and right. Good job dude.\n",
    "Emotions: admiration, love\n",
    "\n",
    "Text: Oh that's right they just came back from the vacation. This is a vacation business trip. What a fuckin' joke.\n",
    "Emotions: amusement\n",
    "\n",
    "Text: Players like this makes me rage quit tbh.\n",
    "Emotions: anger, annoyance\n",
    "\n",
    "Text: If you had a giant rock on your land, and you couldn't stop people climbing, wouldn't you be pissed?\n",
    "Emotions: annoyance, confusion, curiosity\n",
    "\n",
    "Text: This very thing got me diagnosed as ADD. I'm of the drugs now and feeling way much better. \n",
    "Emotions: approval, relief\n",
    "\n",
    "Text: Get rid. This is a toxic relationship that is making you unhappy. You are making all efforts for nothing in return.\n",
    "Emotions: caring, realization\n",
    "\n",
    "Text: Isn't it the same thing? Or at least equally bad?\n",
    "Emotions: confusion\n",
    "\n",
    "Text: It's great that you're a recovering addict, that's cool. Have you ever tried DMT?\n",
    "Emotions: curiosity, admiration\n",
    "\n",
    "Text: I know. And it's very selfish of me to say, but I just wish it was different people that cared.\n",
    "Emotions: desire\n",
    "\n",
    "Text: It's really very upsetting to have parents who dismiss this condition.\n",
    "Emotions: disappointment\n",
    "\n",
    "Text: We got nowhere with that because you only drop one-liners and refuse to actually engage.\n",
    "Emotions: disapproval\n",
    "\n",
    "Text: Apparently, he can't just have sex with anyone because he needed to rape someone.\n",
    "Emotions: disgust\n",
    "\n",
    "Text: I was teased for being a virgin when I was a 6th grader- in 2005\n",
    "Emotions: embarrassment\n",
    "\n",
    "Text: I’d love to get an update on what happened! (When you are ready)\n",
    "Emotions: excitement, love\n",
    "\n",
    "Text: I've also heard that intriguing but also kinda scary\n",
    "Emotions: fear\n",
    "\n",
    "Text: I didn't know that, thank you for teaching me something today!\n",
    "Emotions: gratitude\n",
    "\n",
    "Text: [NAME] death is just so..... senseless. Why? WHY??? The based gods have forsaken us\n",
    "Emotions: grief\n",
    "\n",
    "Text: A surprise turn of events! I'm so glad you heard such great things about yourself!\n",
    "Emotions: joy, surprise\n",
    "\n",
    "Text: I need to just eliminate anxiety and not have cravings\n",
    "Emotions: nervousness\n",
    "\n",
    "Text: I'm going to hold out hope for something minor even though it looked really bad. Just going to wait for the official news.\n",
    "Emotions: optimism\n",
    "\n",
    "Text: Of course I love myself because I'm awesome.\n",
    "Emotions: pride\n",
    "\n",
    "Text: Oh yeah, I forgot about the mean one.\n",
    "Emotions: realization\n",
    "\n",
    "Text: Resetting a dislocated knee hurts like hell but it feels a lot better immediately after.\n",
    "Emotions: relief\n",
    "\n",
    "Text: I sincerely apologize...I’ll delete and please take this upvote\n",
    "Emotions: remorse\n",
    "\n",
    "Text: It's hard to make friends. :( I sit alone.\n",
    "Emotions: sadness\n",
    "\n",
    "Text: I can’t believe that’s real\n",
    "Emotions: surprise\n",
    "\n",
    "Text: I'd say it's pretty uncommon now.\n",
    "Emotions: neutral\n",
    "\n",
    "Reply only with the final comma-separated predominant emotion labels detected. The text to classify is: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RoBERTa Fine-tuned with go_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers model evaluation\n",
    "model = TransformersStrategy(\"SamLowe/roberta-base-go_emotions\")\n",
    "classifier = EmotionClassifier(dataset, model)\n",
    "\n",
    "classifier.evaluate()\n",
    "_ = classifier.create_performance_report(print_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phi 3.5 mini quantized - ZERO SHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama.cpp model evaluation\n",
    "prompt_template = PromptTemplate( system_prompt, zeroshot_user_pre_prompt )\n",
    "model = LlamaCppStrategy(\n",
    "    model_name = \"Phi-3.5-mini-instruct-Q4_K_M-zeroshot\",\n",
    "    model_path = \"models/Phi-3.5-mini-instruct-Q4_K_M.gguf\", \n",
    "    n_ctx = 512,\n",
    "    prompt_template = prompt_template\n",
    ")\n",
    "classifier = EmotionClassifier(dataset, model)\n",
    "classifier.evaluate(verbose=True)\n",
    "report = classifier.create_performance_report(print_report=True, exp_name=\"zeroshot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phi 3.5 mini quantized - FEW SHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama.cpp model evaluation\n",
    "prompt_template = PromptTemplate( system_prompt, fewshot_user_pre_prompt )\n",
    "model = LlamaCppStrategy(\n",
    "    model_name = \"Phi-3.5-mini-instruct-Q4_K_M-few_shot\",\n",
    "    model_path = \"models/Phi-3.5-mini-instruct-Q4_K_M.gguf\", \n",
    "    n_ctx = 1500,\n",
    "    prompt_template = prompt_template\n",
    ")\n",
    "classifier = EmotionClassifier(dataset, model)\n",
    "classifier.evaluate(verbose=True)\n",
    "report = classifier.create_performance_report(print_report=True, exp_name=\"fewshot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llama-3.2-1B-Instruct quantized zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate( system_prompt, zeroshot_user_pre_prompt )\n",
    "model = LlamaCppStrategy(\n",
    "    model_name = \"Llama-3.2-1B-Instruct-Q6_K_L.gguf\",\n",
    "    model_path = \"models/Llama-3.2-1B-Instruct-Q6_K_L.gguf\", \n",
    "    n_ctx = 512,\n",
    "    prompt_template = prompt_template\n",
    ")\n",
    "classifier = EmotionClassifier(dataset, model)\n",
    "classifier.evaluate(verbose=True)\n",
    "report = classifier.create_performance_report(print_report=True, exp_name=\"zeroshot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llama-3.2-1B-Instruct quantized few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate( system_prompt, fewshot_user_pre_prompt )\n",
    "model = LlamaCppStrategy(\n",
    "    model_name = \"Llama-3.2-1B-Instruct-Q6_K_L.gguf\",\n",
    "    model_path = \"models/Llama-3.2-1B-Instruct-Q6_K_L.gguf\", \n",
    "    n_ctx = 1024,\n",
    "    prompt_template = prompt_template\n",
    ")\n",
    "classifier = EmotionClassifier(dataset, model)\n",
    "classifier.evaluate(verbose=True)\n",
    "report = classifier.create_performance_report(print_report=True, exp_name=\"fewshot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepSeek R1 Distill Qwen 1.5B quantized zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As indicated in the DeepSeek R1 Distill Qwen 1.5B model, we shouldn't add a system prompt because it was trained without it, it'd only add noise\n",
    "system_prompt = \"\"\n",
    "user_pre_prompt = f\"\"\"\n",
    "You are an assistant that classifies text into ALL applicable emotions from: {\", \".join(dataset.labels)}. \n",
    "From this text, select the predominant emotions and respond with the final comma-separated predominant emotion names only:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate( system_prompt, user_pre_prompt )\n",
    "model = LlamaCppStrategy(\n",
    "    model_name = \"DeepSeek-R1-Distill-Qwen-1.5B-Q8_0-zero_shot\",\n",
    "    model_path = \"models/DeepSeek-R1-Distill-Qwen-1.5B-Q8_0.gguf\",\n",
    "    prompt_template = prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemma 2 2B quantized zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "You are an assistant that classifies text into ALL applicable emotions from: {\", \".join(dataset.labels)}. \n",
    "\"\"\"\n",
    "user_pre_prompt = f\"\"\"\n",
    "From this text, select the predominant emotions and respond with the final comma-separated predominant emotion names only:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate( system_prompt, user_pre_prompt )\n",
    "model = LlamaCppStrategy(\n",
    "    model_name = \"gemma2-2b-zero_shot\",\n",
    "    model_path = \"models/dolphin-2.9.4-gemma2-2b-Q6_K_L.gguf\",\n",
    "    prompt_template = prompt_template\n",
    ")\n",
    "classifier = EmotionClassifier(dataset, model)\n",
    "classifier.evaluate(verbose=True)\n",
    "report = classifier.create_performance_report(print_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dair-ai emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintain a data length similar to the one used in \"GO_EMOTIONS\"\n",
    "dataset = DatasetHandler(\"dair_emotion\", split=\"test\", sample=0.3, seed=50) \n",
    "print(len(dataset.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data.to_pandas()[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RoBERTa Fine-tuned with go_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers model evaluation\n",
    "model = TransformersStrategy(\"bhadresh-savani/roberta-base-emotion\")\n",
    "classifier = EmotionClassifier(dataset, model)\n",
    "\n",
    "classifier.evaluate()\n",
    "_ = classifier.create_performance_report(print_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing prompts for LLM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You're a helpful and obedient assistant that responds to questions according to the instructions given.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroshot_user_pre_prompt = f\"\"\"\n",
    "Classify text into only ONE emotion label from this list: {\", \".join(dataset.labels)}, replying only with the single emotion label detected. The text is: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshot_user_pre_prompt = f\"\"\"\n",
    "Classify text into only ONE emotion label from this list: {\", \".join(dataset.labels)}, based on the following examples:\n",
    "\n",
    "Text: i feel like damaged goods no one will want me now \n",
    "Emotion: sadness\n",
    "\n",
    "Text: im feeling extremely fabulous with my jacket and shoes aint no bitches gonna bring me down hahah\n",
    "Emotion: joy\n",
    "\n",
    "Text: ive been feeling from my adoring fans that would be teh whole like of you who are my friends here i felt brave and excited and ventrured forth with guitar in hand to a local open mic night\n",
    "Emotion: love\n",
    "\n",
    "Text: i feel so frustrated because i had a long weekday and i dont really have plenty of rest and right now he keeps on coming in the room\n",
    "Emotion: anger\n",
    "\n",
    "Text: i am feeling uncertain of the merits of posting to this blog with the frequency or earnestness i had been over the previous year\n",
    "Emotion: fear\n",
    "\n",
    "Text: i feel as though i am on another adventure and i am more curious about it than anything else\n",
    "Emotion: surprise\n",
    "\n",
    "The text to classify is: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llama-3.2-1B-Instruct quantized - ZERO SHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate( system_prompt, zeroshot_user_pre_prompt )\n",
    "model = LlamaCppStrategy(\n",
    "    model_name = \"Llama-3.2-1B-Instruct-Q6_K_L.gguf\",\n",
    "    model_path = \"models/Llama-3.2-1B-Instruct-Q6_K_L.gguf\", \n",
    "    n_ctx = 256,\n",
    "    prompt_template = prompt_template\n",
    ")\n",
    "classifier = EmotionClassifier(dataset, model)\n",
    "classifier.evaluate(verbose=True)\n",
    "report = classifier.create_performance_report(print_report=True, exp_name=\"zeroshot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llama-3.2-1B-Instruct quantized - FEW SHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate( system_prompt, fewshot_user_pre_prompt )\n",
    "model = LlamaCppStrategy(\n",
    "    model_name = \"Llama-3.2-1B-Instruct-Q6_K_L.gguf\",\n",
    "    model_path = \"models/Llama-3.2-1B-Instruct-Q6_K_L.gguf\", \n",
    "    n_ctx = 512,\n",
    "    prompt_template = prompt_template\n",
    ")\n",
    "classifier = EmotionClassifier(dataset, model)\n",
    "classifier.evaluate(verbose=True)\n",
    "report = classifier.create_performance_report(print_report=True, exp_name=\"fewshot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phi 3.5 mini quantized - ZERO SHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama.cpp model evaluation\n",
    "prompt_template = PromptTemplate( system_prompt, zeroshot_user_pre_prompt )\n",
    "model = LlamaCppStrategy(\n",
    "    model_name = \"Phi-3.5-mini-instruct-Q4_K_M-few_shot\",\n",
    "    model_path = \"models/Phi-3.5-mini-instruct-Q4_K_M.gguf\", \n",
    "    n_ctx = 256,\n",
    "    prompt_template = prompt_template\n",
    ")\n",
    "classifier = EmotionClassifier(dataset, model)\n",
    "classifier.evaluate(verbose=True)\n",
    "report = classifier.create_performance_report(print_report=True, exp_name=\"zeroshot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phi 3.5 mini quantized - FEW SHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama.cpp model evaluation\n",
    "prompt_template = PromptTemplate( system_prompt, fewshot_user_pre_prompt )\n",
    "model = LlamaCppStrategy(\n",
    "    model_name = \"Phi-3.5-mini-instruct-Q4_K_M-few_shot\",\n",
    "    model_path = \"models/Phi-3.5-mini-instruct-Q4_K_M.gguf\", \n",
    "    n_ctx = 512,\n",
    "    prompt_template = prompt_template\n",
    ")\n",
    "classifier = EmotionClassifier(dataset, model)\n",
    "classifier.evaluate(verbose=True)\n",
    "report = classifier.create_performance_report(print_report=True, exp_name=\"fewshot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_report = model.create_performance_report(print_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_template = f\"Respond to this message only replying with the single emotion label you can detect from these emotion labels: {model.dataset_labels} for the following piece of text: \"\n",
    "model.run_inference(sentiment_template + \"My mom said she wants me to go and never return back again\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
